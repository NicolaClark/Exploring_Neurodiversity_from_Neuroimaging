{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting as nplot\n",
    "from nilearn import masking as nimask\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#LOADING IN\n",
    "#one preprocessed scan\n",
    "#nibable image\n",
    "\n",
    "abide_fmri_image_path = 'C:/Users/ahmm9/OneDrive - ITU/ITU/Research_proj/prepros_data/Outputs/ccs/filt_global/func_preproc'\n",
    "adhd200_fmri_image_path = 'C:/Users/ahmm9/OneDrive - ITU/ITU/Research_proj/Adhd200_preproc/NYU_preproc'\n",
    "#abide_fmri_image_path = '../DATA/pre_proc_ABIDE1/func_preproc'\n",
    "#adhd200_fmri_image_path = '../DATA/NYU_preproc'\n",
    "\n",
    "\n",
    "#load in an example image\n",
    "fmri_test_path = abide_fmri_image_path+\"/NYU_0050970_func_preproc.nii\"\n",
    "fmri_test_path_adhd = adhd200_fmri_image_path+\"/sfnwmrda0010001_session_1_rest_1.nii\"\n",
    "img = nib.load(fmri_test_path).get_fdata()\n",
    "\n",
    "print(img.shape)\n",
    "print(f\"The .nii files are stored in memory as numpy's: {type(img)}.\")\n",
    "\n",
    "#load in parcellation mask\n",
    "mask_path = 'data/Yeo2011_7Networks_MNI152_FreeSurferConformed1mm_LiberalMask.nii'\n",
    "img2 = nib.load(mask_path).get_fdata()\n",
    "img2.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data and mask"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#frmi image\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(4, 10, figsize=(12, 3))\n",
    "for i, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(img[:, :, i, 0])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Mask\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(4, 12, figsize=(6, 2))\n",
    "for i, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(img2[:, :, 125 + i, 0])  \n",
    "    # Start from the 31st image (index 30)#TODO still this with different indexing??\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot again?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#load with NILearn\n",
    "abide_ni_image = nimg.load_img(fmri_test_path)\n",
    "adhd200_ni_image = nimg.load_img(fmri_test_path_adhd)\n",
    "ni_mask = nimg.load_img(mask_path)\n",
    "print(abide_ni_image.shape)\n",
    "print(adhd200_ni_image.shape)\n",
    "print(ni_mask.shape)\n",
    "print(ni_mask.affine)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(abide_ni_image.affine)\n",
    "print(adhd200_ni_image.affine)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(abide_ni_image.slicer[:,:,:,5].get_fdata().shape)\n",
    "print(abide_ni_image.slicer[:,:,:,5].get_fdata()[30:40, 30:40, 30])\n",
    "\n",
    "print(adhd200_ni_image.slicer[:, :, :, 5].get_fdata().shape)\n",
    "print(adhd200_ni_image.slicer[:, :, :, 5].get_fdata()[30:40, 30:40, 30])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "adhd200_ni_image.slicer[:, :, :, 5].get_fdata()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#show mask\n",
    "nplot.plot_roi(ni_mask, abide_ni_image.slicer[:,:,:,30])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#show mask\n",
    "nplot.plot_roi(ni_mask, adhd200_ni_image.slicer[:,:,:,30])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape mask to match images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#nilearn reshape dims of mask to match\n",
    "abide_reshaped_mask = nimg.resample_img(ni_mask,target_affine=abide_ni_image.affine, interpolation='nearest',target_shape=abide_ni_image.shape[:3])\n",
    "adhd200_reshaped_mask = nimg.resample_img(ni_mask,target_affine=adhd200_ni_image.affine, interpolation='nearest',target_shape=adhd200_ni_image.shape[:3])\n",
    "print(abide_reshaped_mask.shape)\n",
    "print(adhd200_reshaped_mask.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADHD 200 preprocessing adjustment\n",
    "The adhd200 preprocessing means that the values at edges of the scans are very close to 0, the values have also been normalised, so there are some values around 0 that are actual scan values. We set a small threshold around 0 such that values in this interval are removed, we aim to minimise the size of this interval, such that voxels values that are real, are considered to be part of the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_data = adhd200_ni_image.get_fdata()\n",
    "thresh_ = 0.001\n",
    "between_thresh = [i>thresh_ or i < -thresh_ for i in image_data.flatten()]\n",
    "plt.hist(image_data.flatten()[between_thresh],bins = 10000);\n",
    "plt.xlim(-0.5,0.5);\n",
    "print(np.std(image_data.flatten()[between_thresh]))\n",
    "print(np.std(image_data.flatten()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.hist(image_data.flatten(),bins = 1000);\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nplot.plot_img(adhd200_ni_image.slicer[:,:,:,20],threshold=0.001)\n",
    "nplot.plot_img(adhd200_ni_image.slicer[:,:,:,20],threshold=0.0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#plot the mask onto one slice of the frmi image\n",
    "nplot.plot_roi(adhd200_reshaped_mask, adhd200_ni_image.slicer[:,:,:,5])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#creates a mask dictionary with separate the regions as keys and the region masks as values\n",
    "def create_parcellation_masks(nifti_mask, nifti_image):\n",
    "    data = nifti_mask.get_fdata().astype(int)\n",
    "    # Create a dictionary to store each mask\n",
    "    masks = {}\n",
    "    for value in range(1, 8):\n",
    "        masks[value] = nib.Nifti1Image((data == value).astype(float), nifti_image.affine) # Create a mask for each unique value\n",
    "    return masks\n",
    "\n",
    "abide_mask_dict = create_parcellation_masks(abide_reshaped_mask,abide_ni_image)\n",
    "adhd200_mask_dict = create_parcellation_masks(adhd200_reshaped_mask,adhd200_ni_image)\n",
    "\n",
    "print(abide_mask_dict[1].shape)\n",
    "print(adhd200_mask_dict[1].shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mask_reasonable_shape = abide_mask_dict[1].get_fdata().astype(int)[:,:,:,0]\n",
    "not_brain = (mask_reasonable_shape == 0).sum()\n",
    "brain = (mask_reasonable_shape != 0).sum()\n",
    "print(brain,not_brain) # not brain is relative to parcellation\n",
    "print(\"percentage of brain masked\",(brain/(brain+not_brain))*100,\"%\")\n",
    "\n",
    "mask_reasonable_shape = adhd200_mask_dict[1].get_fdata().astype(int)[:,:,:,0]\n",
    "not_brain = (mask_reasonable_shape == 0).sum()\n",
    "brain = (mask_reasonable_shape != 0).sum() ##TODO not accurate\n",
    "print(brain,not_brain) # not brain is relative to parcellation\n",
    "print(\"percentage of brain masked\",(brain/(brain+not_brain))*100,\"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#applies mask to image\n",
    "def apply_mask(image,mask):\n",
    "    output_dict = {}\n",
    "    for i in range(1,8):\n",
    "        stack = []\n",
    "        masked = nimask.apply_mask(image, mask[i])\n",
    "        row_check = masked[0][masked[0] != 0]\n",
    "        for row in masked:\n",
    "            if image.shape == (49, 58, 47, 172):\n",
    "                masked_no_zeros = row[(row < -0.001) | (row > 0.001)]\n",
    "            else:\n",
    "                masked_no_zeros = row[row != 0]\n",
    "            while len(masked_no_zeros) != len(row_check):\n",
    "                mean_value = np.mean(row)\n",
    "                masked_no_zeros = np.concatenate((masked_no_zeros,mean_value),axis=None)\n",
    "            stack.append(masked_no_zeros)\n",
    "        output_dict[i] = np.array(stack)\n",
    "    return output_dict    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_voxel_count_per_region(onescan_data):\n",
    "    voxel_count = []\n",
    "    for region in range(len(onescan_data.keys())):\n",
    "        voxel_count.append(onescan_data[region+1].shape[1])\n",
    "    return voxel_count\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:49:34.596594Z",
     "start_time": "2024-12-02T17:49:33.968508Z"
    }
   },
   "source": [
    "#get all images into list\n",
    "all_images = []\n",
    "\n",
    "#seg = pd.read_csv(\"ABIDE_phenotypic_NYU.csv\")\n",
    "labels = []\n",
    "\n",
    "for phenotypic in os.listdir(\"data/selected_participants\"):\n",
    "    seg = pd.read_csv(\"data/selected_participants/\"+phenotypic)\n",
    "    print(phenotypic)\n",
    "    if phenotypic.startswith(\"ABIDE_\"):\n",
    "        image_path = abide_fmri_image_path\n",
    "        id_name = \"SUB_ID\"\n",
    "        dx_name = \"DX_GROUP\"\n",
    "        index_1 = 4\n",
    "        index_2 = 11\n",
    "        label_offset = 0\n",
    "    else:\n",
    "        image_path = adhd200_fmri_image_path\n",
    "        id_name = \"ScanDir ID\"\n",
    "        dx_name = \"DX\"\n",
    "        index_1 = 8\n",
    "        index_2 = 15\n",
    "        label_offset = 10\n",
    "    for filename in os.listdir(image_path):\n",
    "        if filename.endswith('.nii') or filename.endswith('.nii.gz'):\n",
    "            file_path = os.path.join(image_path, filename)\n",
    "            sub_id = int(filename[index_1:index_2])\n",
    "            dx_group = seg[seg[id_name] == sub_id][dx_name]\n",
    "            if not dx_group.empty:\n",
    "                if id_name == \"SUB_ID\" and (pd.notna(seg.iloc[0][\"COMORBIDITY\"]) and seg.iloc[0][\"COMORBIDITY\"] != \"\"):\n",
    "                    labels.append(3)\n",
    "                else:\n",
    "                    labels.append(label_offset+int(dx_group.iloc[0]))\n",
    "                img = nimg.load_img(file_path)\n",
    "                all_images.append(img)\n",
    "print(np.array(all_images).shape)\n",
    "print(np.array(labels).shape)\n",
    "print(np.array(labels))\n",
    "print(np.unique(labels))\n",
    "print(np.sum(np.array(labels) == 3))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABIDE_ASD_ADHD_Comorbid_phenotypic_NYU.csv\n",
      "ABIDE_pure_ASD_phenotypic_NYU.csv\n",
      "ABIDE_TD_phenotypic_NYU.csv\n",
      "ADHD200_pure_ADHD_phenotypic_NYU.csv\n",
      "ADHD200_TD_phenotypic_NYU.csv\n",
      "(244,)\n",
      "(244,)\n",
      "[ 3  3  3  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2 13 13 12 13 13 11 11 11 11 13 13 11 11 11 11\n",
      " 11 11 11 11 11 11 13 13 13 13 11 13 13 11 11 11 11 11 11 11 11 13 13 13\n",
      " 11 13 13 11 11 11 11 11 11 11 11 13 13 13 13 11 11 11 11 11 11 11 11 13\n",
      " 11 11 13 13 13 13 13 11 11 13 13 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10]\n",
      "[ 1  2  3 10 11 12 13]\n",
      "5\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:49:42.083718Z",
     "start_time": "2024-12-02T17:49:42.077717Z"
    }
   },
   "source": [
    "#check affine is same for all images\n",
    "print(len(all_images))\n",
    "prev_img = all_images[0]\n",
    "for img in all_images:\n",
    "    if (prev_img.affine != img.affine).any():\n",
    "        print(\"different\")\n",
    "    prev_img = img\n",
    "    \n",
    "print(all_images[0].affine)\n",
    "print(all_images[240].affine)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "different\n",
      "[[  -3.   -0.   -0.   90.]\n",
      " [  -0.    3.   -0. -126.]\n",
      " [   0.    0.    3.  -72.]\n",
      " [   0.    0.    0.    1.]]\n",
      "[[  -4.   -0.   -0.   96.]\n",
      " [  -0.    4.   -0. -132.]\n",
      " [   0.    0.    4.  -70.]\n",
      " [   0.    0.    0.    1.]]\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:21.178395400Z",
     "start_time": "2024-12-02T17:50:28.541129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "affine_ref = [[  -3.,   -0.,   -0.,   90.],\n",
    " [  -0. ,   3. ,  -0., -126.],\n",
    " [   0.,    0.,    3.,  -72.],\n",
    " [   0.,    0. ,   0.,    1.]]\n",
    "\n",
    "all_masked_images = []\n",
    "start_index = 0\n",
    "# running mask apply, save every 10th iteration, can be restarted and interrupted\n",
    "try:\n",
    "    with open('masked_image.pkl', 'rb') as f:\n",
    "        print(f)\n",
    "        all_masked_images = pickle.load(f)\n",
    "        start_index = len(all_masked_images)\n",
    "        print(f\"Resuming from index {start_index}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No previous save found, starting from scratch\")\n",
    "    \n",
    "for i in range(start_index,len(all_images)):\n",
    "    if (all_images[i].affine == affine_ref).all():\n",
    "        all_masked_images.append(apply_mask(all_images[i],abide_mask_dict))\n",
    "    else:\n",
    "        all_masked_images.append(apply_mask(all_images[i],adhd200_mask_dict))\n",
    "    if (i % 10 == 0):\n",
    "        with open('masked_image.pkl', 'wb') as f:\n",
    "            pickle.dump(all_masked_images,f)\n",
    "        print(\"saved at index\", i)\n",
    "\n",
    "print(\"Applied mask to all images\")\n",
    "print(len(all_images) == len(all_masked_images))\n",
    "print(all_images[0].shape[3] == len(all_masked_images[0][1]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='masked_image.pkl'>\n",
      "Resuming from index 1\n",
      "saved at index 10\n",
      "saved at index 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(start_index,\u001B[38;5;28mlen\u001B[39m(all_images)):\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (all_images[i]\u001B[38;5;241m.\u001B[39maffine \u001B[38;5;241m==\u001B[39m affine_ref)\u001B[38;5;241m.\u001B[39mall():\n\u001B[1;32m---> 20\u001B[0m         all_masked_images\u001B[38;5;241m.\u001B[39mappend(\u001B[43mapply_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_images\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mabide_mask_dict\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m         all_masked_images\u001B[38;5;241m.\u001B[39mappend(apply_mask(all_images[i],adhd200_mask_dict))\n",
      "Cell \u001B[1;32mIn[42], line 6\u001B[0m, in \u001B[0;36mapply_mask\u001B[1;34m(image, mask)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m8\u001B[39m):\n\u001B[0;32m      5\u001B[0m     stack \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 6\u001B[0m     masked \u001B[38;5;241m=\u001B[39m \u001B[43mnimask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     row_check \u001B[38;5;241m=\u001B[39m masked[\u001B[38;5;241m0\u001B[39m][masked[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m masked:\n",
      "File \u001B[1;32m~\\Documents\\Github\\AML--NLP-\\venv\\Lib\\site-packages\\nilearn\\masking.py:809\u001B[0m, in \u001B[0;36mapply_mask\u001B[1;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001B[0m\n\u001B[0;32m    807\u001B[0m mask, mask_affine \u001B[38;5;241m=\u001B[39m load_mask_img(mask_img)\n\u001B[0;32m    808\u001B[0m mask_img \u001B[38;5;241m=\u001B[39m new_img_like(mask_img, mask, mask_affine)\n\u001B[1;32m--> 809\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_mask_fmri\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    810\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    811\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask_img\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    812\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    813\u001B[0m \u001B[43m    \u001B[49m\u001B[43msmoothing_fwhm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msmoothing_fwhm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    815\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Github\\AML--NLP-\\venv\\Lib\\site-packages\\nilearn\\masking.py:858\u001B[0m, in \u001B[0;36mapply_mask_fmri\u001B[1;34m(imgs, mask_img, dtype, smoothing_fwhm, ensure_finite)\u001B[0m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    856\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m series\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;28;01mif\u001B[39;00m series\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mfloat32\n\u001B[1;32m--> 858\u001B[0m series \u001B[38;5;241m=\u001B[39m \u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m imgs_img  \u001B[38;5;66;03m# frees a lot of memory\u001B[39;00m\n\u001B[0;32m    861\u001B[0m \u001B[38;5;66;03m# Delayed import to avoid circular imports\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Github\\AML--NLP-\\venv\\Lib\\site-packages\\nilearn\\_utils\\numpy_conversions.py:121\u001B[0m, in \u001B[0;36mas_ndarray\u001B[1;34m(arr, copy, dtype, order)\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    117\u001B[0m             \u001B[38;5;66;03m# First load data from disk without changing order\u001B[39;00m\n\u001B[0;32m    118\u001B[0m             \u001B[38;5;66;03m# Changing order while reading through a memmap is incredibly\u001B[39;00m\n\u001B[0;32m    119\u001B[0m             \u001B[38;5;66;03m# inefficient.\u001B[39;00m\n\u001B[0;32m    120\u001B[0m             ret \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(arr, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 121\u001B[0m             ret \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    124\u001B[0m     ret \u001B[38;5;241m=\u001B[39m _asarray(arr, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n",
      "File \u001B[1;32m~\\Documents\\Github\\AML--NLP-\\venv\\Lib\\site-packages\\nilearn\\_utils\\numpy_conversions.py:35\u001B[0m, in \u001B[0;36m_asarray\u001B[1;34m(arr, dtype, order)\u001B[0m\n\u001B[0;32m     33\u001B[0m         ret \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mview(dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 35\u001B[0m         ret \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:22.959071Z",
     "start_time": "2024-12-02T17:55:22.955417Z"
    }
   },
   "source": [
    "def threshold_per_participant(data):\n",
    "    \"\"\"each participant, whole timeframe\"\"\"\n",
    "    thresholds = np.zeros((len(data),7))\n",
    "    for i in range(len(data)): #each participant\n",
    "        voxel_sum = np.empty(7)\n",
    "        voxel_count = [abc * data[i][1].shape[0] for abc in compute_voxel_count_per_region(data[i])]\n",
    "        for k in range(len(data[i].keys())): #region\n",
    "            voxel_sum[k] = np.sum(data[i][k+1])\n",
    "        means = voxel_sum/voxel_count\n",
    "        thresholds[i] = means\n",
    "    return thresholds"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:24.719968Z",
     "start_time": "2024-12-02T17:55:24.601048Z"
    }
   },
   "source": [
    "threshold_participant = threshold_per_participant(all_masked_images)\n",
    "print(\"participant (participants,thresholds): \", threshold_participant.shape)\n",
    "GTP_SHAPE = threshold_participant[0].shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant (participants,thresholds):  (30, 7)\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:43.456091Z",
     "start_time": "2024-12-02T17:55:43.451196Z"
    }
   },
   "source": [
    "## New version\n",
    "def binarise(data,thresholds):\n",
    "    bin_by_group = {1:[],2:[],3:[],10:[],11:[],12:[],13:[]}\n",
    "\n",
    "    for scan_num,one_scan in enumerate(data):# for each participant\n",
    "        image_label = labels[scan_num]\n",
    "        # Binarize for single participant\n",
    "        one_participant_bin = np.array(pd.DataFrame.from_dict(apply_threshold(one_scan,thresholds[scan_num]),orient=\"index\"))\n",
    "        bin_by_group[image_label].append(one_participant_bin)\n",
    "\n",
    "    for group in bin_by_group:\n",
    "        if (len(bin_by_group[group]) > 0):\n",
    "            bin_by_group[group] = np.concatenate(bin_by_group[group],axis=1,dtype=int)\n",
    "    return bin_by_group\n",
    "\n",
    "def apply_threshold(participant, thresholds):\n",
    "    binarized_participant = dict()\n",
    "    if thresholds.shape == GTP_SHAPE:\n",
    "        for k in participant.keys():            \n",
    "            mean_image = (np.mean(participant[k], axis = 1)) - thresholds[k-1]\n",
    "            binarized_participant[k] = np.where(mean_image > 0, 1, -1)\n",
    "    else:\n",
    "        raise ValueError(\"thresholds does have correct dimensions, found dimension:\", thresholds.shape )\n",
    "    return binarized_participant"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:46.392057Z",
     "start_time": "2024-12-02T17:55:46.019514Z"
    }
   },
   "source": [
    "binarized = binarise(all_masked_images,threshold_participant)\n",
    "binarized[1].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2800)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:55:49.072949Z",
     "start_time": "2024-12-02T17:55:49.058284Z"
    }
   },
   "source": [
    "#save\n",
    "for i in binarized.keys():\n",
    "    np.savetxt(f\"data/reader_output_matlab_input/Binarized_Data_Group_{i}\",binarized[i],fmt=\"%d\",delimiter=\",\")"
   ],
   "outputs": [],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
